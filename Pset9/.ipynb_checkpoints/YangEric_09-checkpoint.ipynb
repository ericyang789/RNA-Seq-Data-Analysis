{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# homework 09: the return of the ten Arcs\n",
    "* Eric Yang\n",
    "* 11/07/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: given sequencing reads and locus information, estimate isoform abundances by expectation maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Arc locus structure and reads Lestrade generated\n",
    "with open('w09-data.out','r') as infile:\n",
    "    L = np.zeros(10) # transcript lengths\n",
    "    next(infile)\n",
    "    for i in range(10):\n",
    "        line = next(infile).split()\n",
    "        L[i] = line[2]\n",
    "        L = L.astype(int)\n",
    "    next(infile)\n",
    "    next(infile)\n",
    "    lestrade_reads = np.zeros(10) # read sequences, sum = 1000000\n",
    "    for i in range(10):\n",
    "        line = next(infile).split()\n",
    "        lestrade_reads[i] = line[1]\n",
    "        lestrade_reads = lestrade_reads.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. write a simulator as a positive control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_reads(N, theta, n_segments):\n",
    "    '''\n",
    "    N is the number of reads to sample\n",
    "    theta is an array of 2 arrays, includes nu (nucleotide abundance), L (transcript lengths) \n",
    "    simulate reads\n",
    "    returns read counts for each segment, array with length = number of segments\n",
    "    '''\n",
    "    nu = theta[0] # nucleotide abundance\n",
    "    L = theta[1] # transcript lengths\n",
    "    n_isoforms = len(L) # number of isoforms\n",
    "    reads = np.zeros(n_segments)\n",
    "    transcripts = np.random.choice(n_isoforms, p=nu, size=N) # sample N transcripts\n",
    "    for i in range(N):\n",
    "        start = np.random.randint(transcripts[i], transcripts[i]+L[transcripts[i]])\n",
    "        reads[start%n_segments] += 1\n",
    "    return reads.astype(int) # array with length = number of segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the simulate_reads function, let's generate test reads given known model parameters (transcript abundances and isoform lengths), so we can test our algorithm later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make up known transcript abundances as positive control\n",
    "n_segments = 10\n",
    "np.random.seed(5)\n",
    "t_abundances = np.random.dirichlet(np.ones(n_segments))\n",
    "\n",
    "# convert transcript abundances to nucleotide abundance\n",
    "# we'll use the isoform lengths given in pset\n",
    "n_abundances = t_abundances * L / np.sum(t_abundances * L)\n",
    "theta = np.array([n_abundances, L])\n",
    "\n",
    "# test N = 1000000\n",
    "N = 1000000\n",
    "test_reads = simulate_reads(N, theta, n_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true transcript abundances for positive control:  [0.02671547 0.21773719 0.02464631 0.26697534 0.07133146 0.10069017\n",
      " 0.1545373  0.07776445 0.03747475 0.02212756]\n",
      "true isoform lengths for positive control:  [4 2 3 4 4 3 2 2 3 3]\n",
      "test reads:  [ 29601  91130  92505 108869 124613 151480 203419 138343  39662  20378]\n"
     ]
    }
   ],
   "source": [
    "print(\"true transcript abundances for positive control: \", t_abundances)\n",
    "print(\"true isoform lengths for positive control: \", L)\n",
    "print(\"test reads: \", test_reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. calculate the log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(R, theta):\n",
    "    '''\n",
    "    R is an array of reads for each transcript \n",
    "    theta is an array of 2 arrays, includes nu (nucleotide abundance), L (transcript lengths) \n",
    "    calculates and returns the total log likelihood of the reads given model\n",
    "    '''\n",
    "    nu = theta[0] # nucleotide abundance\n",
    "    L = theta[1].astype(int) # transcript lengths\n",
    "    n_isoforms = len(L) # number of isoforms\n",
    "    n_segments = len(R) # number of segments\n",
    "    structure = isoform_segments(L, n_segments) # dictionary storing isoform(key) - contained segments(value) relationship\n",
    "    \n",
    "    # calculate log likelihood for each segment\n",
    "    ll = np.zeros(n_segments) \n",
    "    for i in range(n_segments):\n",
    "        prob_s = 0\n",
    "        for j in range(n_isoforms):\n",
    "            if i in structure[j]:\n",
    "                prob_s += nu[j]/L[j]\n",
    "        ll[i] = np.log(prob_s)\n",
    "    total = np.sum(R * ll)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isoform_segments(L, n_segments):\n",
    "    '''\n",
    "    L is an array containing lengths for each transcript\n",
    "    n_segments is an int denoting number of segments in loci structure\n",
    "    create dictionary storing isoform(key) - contained segments(value) relationship\n",
    "    '''\n",
    "    structure = {}\n",
    "    for i in range(len(L)):\n",
    "        end = i + L[i]\n",
    "        if end > n_segments:\n",
    "            segments = set(range(i,n_segments))\n",
    "            segments |= set(range(0, end%n_segments))\n",
    "        else: \n",
    "            segments = set(range(i,end))\n",
    "        structure[i] = segments\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the log_likelihood function, let's calculate the total log likelihood of the generated test data set above given the known isoform lengths and transcript abundances (also printed above in part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2134463.083894684"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ll = log_likelihood(test_reads, theta)\n",
    "test_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total log likelihood of the generated test data set above given the known parameters is -2134463."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lestrade's naive analysis\n",
    "def naive(n_segments, reads, L):\n",
    "    # use our reads, isoform lengths, and 10 segments\n",
    "    T = n_segments\n",
    "    S = T    # S = T : there are T transcripts (Arc1..Arc10), S segments (A..J)\n",
    "    r = reads\n",
    "\n",
    "    # Count how often each segment A..J is used in the isoforms i\n",
    "    # We'll use that to split observed read counts across the isoforms\n",
    "    # that they might have come from.\n",
    "    segusage = np.zeros(S).astype(int)\n",
    "    for i in range(T):\n",
    "        for j in range(i,i+L[i]): \n",
    "            segusage[j%S] += 1\n",
    "\n",
    "    # Naive analysis:\n",
    "    c  = np.zeros(T)\n",
    "    for i in range(T):\n",
    "        for k in range(i,i+L[i]):\n",
    "            c[i] += (1.0 / float(segusage[k%S])) * float(r[k%S])  # For each read k, assume read k-> segment j,\n",
    "                                                                  # and assign 1/usage count to each transcript\n",
    "                                                                  # that contains segment j.\n",
    "    Z       = np.sum(c)\n",
    "    est_nu  = np.divide(c, Z)       # nucleotide abundance\n",
    "\n",
    "    est_tau = np.divide(est_nu, L)  # convert to TPM, transcript abundance\n",
    "    est_tau = np.divide(est_tau, np.sum(est_tau))\n",
    "\n",
    "    return est_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript abundance estimated by lestrade's naive method:  [0.08179151 0.09326017 0.11036968 0.13649302 0.135195   0.13806968\n",
      " 0.13017446 0.08290765 0.04051372 0.05122509]\n",
      "true transcript abundance:  [0.02671547 0.21773719 0.02464631 0.26697534 0.07133146 0.10069017\n",
      " 0.1545373  0.07776445 0.03747475 0.02212756]\n"
     ]
    }
   ],
   "source": [
    "lestrade_tau = naive(n_segments, test_reads, L)\n",
    "print(\"transcript abundance estimated by lestrade's naive method: \", lestrade_tau)\n",
    "print(\"true transcript abundance: \", t_abundances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lestrade's transcript abundance estimates are very different from the true transcript abundances. Let's calculate the log likelihood given Lestrade's estimate compared to the log likelihood given true transcript abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2150389.5134304026"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lestrade_nu = lestrade_tau * L / np.sum(lestrade_tau * L)\n",
    "lestrade_theta = np.array([lestrade_nu, L])\n",
    "lestrade_ll = log_likelihood(test_reads, lestrade_theta)\n",
    "lestrade_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total log likelihood of the reads generated by Lestrade's model given the known parameters is -2150389."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_ratio = np.exp(test_ll-lestrade_ll)\n",
    "likelihood_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the true transcript parameter values is much more likely than Lestrade's estimate. I will explore in part 3 the missteps in Lestrade's model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. estimate isoform abundances by EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(R, theta):\n",
    "    '''\n",
    "    R is an array of reads for each transcript \n",
    "    theta is an array of 2 arrays, includes nu (nucleotide abundance), L (transcript lengths) \n",
    "    calculates and returns expected counts \n",
    "    '''\n",
    "    nu = theta[0] # nucleotide abundance\n",
    "    L = theta[1].astype(int) # transcript lengths\n",
    "    n_isoforms = len(L) # number of isoforms\n",
    "    n_segments = len(R) # number of segments\n",
    "    structure = isoform_segments(L, n_segments) # dictionary storing isoform(key) - contained segments(value) relationship\n",
    "    \n",
    "    # calculate expected counts for each segment\n",
    "    counts = np.zeros(n_isoforms)\n",
    "    for i in range(n_segments):\n",
    "        probs = np.zeros(n_isoforms)\n",
    "        for j in range(n_isoforms):\n",
    "            if i in structure[j]:\n",
    "                probs[j] = nu[j]/L[j]\n",
    "        probs /= np.sum(probs)\n",
    "        counts += R[i] * probs \n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximization(C):\n",
    "    '''\n",
    "    given C (read counts)  \n",
    "    caluclate the updated nu (nucleotide abundances)\n",
    "    '''\n",
    "    return C/np.sum(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(R, theta, thresh=0.00001):\n",
    "    '''\n",
    "    Given R (reads) and \n",
    "    theta (nucleotide abundances and transcript lengths),\n",
    "    Run EM until convergence\n",
    "    '''\n",
    "    # this problem is convex, so only need to try one initial condition\n",
    "    LL = 0\n",
    "    old_LL = float(\"inf\")\n",
    "    while abs(LL-old_LL) > thresh: # use absolute difference in case \"skating\" along likelihood surface\n",
    "        old_LL = LL\n",
    "        c = expectation(R, theta)\n",
    "        theta[0] = maximization(c)\n",
    "        LL = log_likelihood(R,theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply EM script to Lestrade reads data \n",
    "# random initialization for nu\n",
    "t_abundances = np.random.dirichlet(np.ones(n_segments))\n",
    "n_abundances = t_abundances * L / np.sum(t_abundances * L)\n",
    "theta = np.array([n_abundances, L])\n",
    "\n",
    "# run EM\n",
    "pred = expectation_maximization(lestrade_reads, theta)\n",
    "nu_pred = pred[0]\n",
    "tau_pred = (nu_pred/L)/np.sum(nu_pred/L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript abundance estimates\n",
      "Arc #      Lestrade    EM\n",
      "Arc1        0.085    0.142\n",
      "Arc2        0.077    0.019\n",
      "Arc3        0.080    0.084\n",
      "Arc4        0.096    0.053\n",
      "Arc5        0.111    0.023\n",
      "Arc6        0.129    0.163\n",
      "Arc7        0.151    0.313\n",
      "Arc8        0.123    0.095\n",
      "Arc9        0.078    0.076\n",
      "Arc10       0.071    0.032\n"
     ]
    }
   ],
   "source": [
    "# print results and compare to Lestrade's\n",
    "lestrade_pred = naive(10, lestrade_reads, L)\n",
    "Tlabel = [\"Arc{}\".format(d) for d in range(1,11) ] # ['Arc1'..'Arc10'] : the labels for Arc transcript isoforms\n",
    "print(\"Transcript abundance estimates\")\n",
    "print(\"Arc #      Lestrade    EM\")\n",
    "for i in range(10):\n",
    "    print (\"{0:10s}  {1:5.3f}    {2:5.3f}\".format(Tlabel[i], lestrade_pred[i], tau_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the table above, the transcipt abundance estimates from the EM model is very different than Lestrade's, and it is clear that not all of the transcripts are expressed at the same level. The most abundant two transcript are Arc7 (0.313) and Arc 6 (0.163), accounting for 0.476 of the population. The least two abundant transcripts are Arc 2 (0.019) and Arc 5 (0.023). There is at least a log fold expression difference between the most abundant and least abundant transcripts. Lestrade's issue was the failure to account for the impact of transcript length on read sampling. Since longer transcripts are more likely to be sampled, it is inappropriate to assign a uniform probability for a segment j belonging in transcript i across all transcripts containing segment j. This uniform assignment of likelihood leads to a more uniform transcript abundance estimate across isoforms, like we see in Lestrade's results. The takeaway here is that we have to consider isoform length along side nucleotide abundance information during read mapping to achieve more robust predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
