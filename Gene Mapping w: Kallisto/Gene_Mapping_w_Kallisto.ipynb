{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCB112 pset02: the adventure of the ten Arcs\n",
    "* Eric Yang\n",
    "* 09/21/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kallisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kallisto 0.46.2\r\n",
      "\r\n",
      "Usage: kallisto <CMD> [arguments] ..\r\n",
      "\r\n",
      "Where <CMD> can be one of:\r\n",
      "\r\n",
      "    index         Builds a kallisto index \r\n",
      "    quant         Runs the quantification algorithm \r\n",
      "    bus           Generate BUS files for single-cell data \r\n",
      "    pseudo        Runs the pseudoalignment step \r\n",
      "    merge         Merges several batch runs \r\n",
      "    h5dump        Converts HDF5-formatted results to plaintext\r\n",
      "    inspect       Inspects and gives information about an index\r\n",
      "    version       Prints version information\r\n",
      "    cite          Prints citation information\r\n",
      "\r\n",
      "Running kallisto <CMD> without arguments prints usage information for <CMD>\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reproduce Moriarty's result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Arc1\r\n",
      "TAGCCTTCATCCTGTGTGGGTGTGGGCTCCCACTCGGTTCTAGGTCAGTACGAGCCTGCA\r\n",
      "CCTTCCTGTGGAGCAAGTCCGTCTCCTTCCTGCGCTCATACCTAATGAGTGAGGCGCTAA\r\n",
      "CTGCCCCTATGGGCGGATGGACCCAACTAGCCCATGAGTCGACCACCAGAGAACCTTGAT\r\n",
      "CCGTCCTTGCCAGCATTAATGAGCATTCTCTTAGTTTTGACAGCGGGGCGATTCATGAGA\r\n",
      "AACATATGCTTCCCCTTGTTCGAGCCGGATCACTTGAGTCGATACGTCTCCGGGGGTCTC\r\n",
      "CGGGGAAGCCTCAGGGACCTAGTCCGATAACAGACACCTATATGCTAGTTGCTGGTGGAT\r\n",
      "TGTGTTTCAATCTTCTTCCAAGAAGTGCACGTAAACATGGGGGTGTCGGTTATGGAAAGG\r\n",
      "ATACCTATCTCCAGAATCAGTAACAAGTCAATGTAACGGGACGCACGGGACTCACCATCT\r\n",
      "CTAGTATGCACTCTGCCGATGGGAACTTCGAATGCGCGATGCCTCTATTTCCAGTTGTAG\r\n"
     ]
    }
   ],
   "source": [
    "# Explore fasta file\n",
    "! gunzip -c arc.fasta.gz | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@read0\r\n",
      "GTATCCGTGAATAACCCACCTAATGCATGGGCGTTCAAATGGTGGTTATGCTAAAAAAGACGTGGGAATTTTGCA\r\n",
      "+\r\n",
      "???????????????????????????????????????????????????????????????????????????\r\n",
      "@read1\r\n",
      "AAAGATACCTACGAGCTCGAACTAGCACTATGACAAACATGCTGCGCGTCCACTTCCCACCGTAACGCCGAAGTG\r\n",
      "+\r\n",
      "???????????????????????????????????????????????????????????????????????????\r\n",
      "@read2\r\n",
      "GACCCCCGGAGACGTATCGACTCAAGTGATCCGGCTCGAACAAGGGGAAGCATATGTTTCTCATGAATCGCCCCG\r\n",
      "gunzip: error writing to output: Broken pipe\r\n",
      "gunzip: arc.fastq.gz: uncompress failed\r\n"
     ]
    }
   ],
   "source": [
    "# Explore fastq file\n",
    "! gunzip -c arc.fastq.gz | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[build] loading fasta file arc.fasta.gz\r\n",
      "[build] k-mer length: 31\r\n",
      "[build] counting k-mers ... done.\r\n",
      "[build] building target de Bruijn graph ...  done \r\n",
      "[build] creating equivalence classes ...  done\r\n",
      "[build] target de Bruijn graph has 19 contigs and contains 10000 k-mers \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Build kallisto index of transcriptome\n",
    "! kallisto index -i transcripts.idx arc.fasta.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 10,000\n",
      "[index] number of equivalence classes: 26\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: arc.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,981 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Map reads against transcriptome\n",
    "! kallisto quant -i transcripts.idx -o output --single -l 150 -s 20 arc.fastq.gz  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_id\tlength\teff_length\test_counts\ttpm\n",
      "\n",
      "Arc1\t4000\t3851\t3348.79\t24514.5\n",
      "\n",
      "Arc2\t2000\t1851\t3574.56\t54440.7\n",
      "\n",
      "Arc3\t3000\t2851\t28065.2\t277510\n",
      "\n",
      "Arc4\t4000\t3851\t10597.7\t77579.1\n",
      "\n",
      "Arc5\t4000\t3851\t12526.7\t91700.1\n",
      "\n",
      "Arc6\t3000\t2851\t1953.39\t19315.2\n",
      "\n",
      "Arc7\t2000\t1851\t5579.78\t84980.4\n",
      "\n",
      "Arc8\t2000\t1851\t5700.81\t86823.7\n",
      "\n",
      "Arc9\t3000\t2851\t3052.55\t30183.8\n",
      "\n",
      "Arc10\t3000\t2851\t25581.6\t252953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at abundance.tsv output, check match with moriarty data\n",
    "with open(\"output/abundance.tsv\",'r') as infile:   \n",
    "    for line in infile:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tpms are in the same order of magnitude as Moriarty's results, essentially matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate an Arc transciptome and RNA-seq reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Arc locus \n",
    "S         = 10           # Number of segments in the Arc locus (A..J)\n",
    "T         = S            # Number of different transcripts (the same, one starting on each segment, 1..10)\n",
    "N         = 100000       # total number of observed reads we generate\n",
    "len_S     = 1000         # length of each segment (nucleotides)\n",
    "len_Arc   = len_S * S    # total length of the Arc locus (nucleotides)\n",
    "len_R     = 75           # read length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10kb Arc locus DNA sequence\n",
    "np.random.seed(5)\n",
    "arc_seq = ''.join(np.random.choice(list('ACGT'), len_Arc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arc locus length and abundance\n",
    "L = [4 * len_S, 2 * len_S, 3 * len_S, 4 * len_S, 4 * len_S,\n",
    "     3 * len_S, 2 * len_S, 2 * len_S, 3 * len_S, 3 * len_S,]\n",
    "V = [0.0081, 0.0391, 0.2911, 0.1121, 0.1271, 0.0081, 0.0591, 0.0601, 0.0221, 0.2731] \n",
    "#added 0.0001 to each vi to make sum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Arc1 to Arc10 transcipts\n",
    "arc_trans = {}\n",
    "with open('arc_sim.fasta','w') as outfile:\n",
    "    for arc in range(S):\n",
    "        name = '>Arc' + str(arc + 1)\n",
    "        start = arc * len_S\n",
    "        end = start + L[arc]\n",
    "        if end > len_Arc:\n",
    "            seq = arc_seq[start:len_Arc] + arc_seq[0:end%len_Arc]\n",
    "        else: \n",
    "            seq = arc_seq[start:end]\n",
    "        arc_trans[name] = seq\n",
    "        outfile.write(name + '\\n')\n",
    "        outfile.write(seq + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reads\n",
    "with open('arc_sim.fastq','w') as outfile:\n",
    "    for read in range(N):\n",
    "        # sample transcipt\n",
    "        i = np.random.choice(range(0,T), p=V) # generates integer between 0-9 based on nucleotide abundance\n",
    "        # pick random start position\n",
    "        start = np.random.randint(0, L[i] - len_R)\n",
    "        seq = arc_trans['>Arc' + str(i + 1)][start:start + len_R] \n",
    "        # above: need to add one to convert python 0-9 indexing to arc 1-10\n",
    "        outfile.write('@read' + str(read) + '\\n')\n",
    "        outfile.write(seq + '\\n')\n",
    "        outfile.write('+' + '\\n')\n",
    "        outfile.write('I' * len_R + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test kallisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[build] loading fasta file arc_sim.fasta\r\n",
      "[build] k-mer length: 31\r\n",
      "[build] counting k-mers ... done.\r\n",
      "[build] building target de Bruijn graph ...  done \r\n",
      "[build] creating equivalence classes ...  done\r\n",
      "[build] target de Bruijn graph has 19 contigs and contains 10000 k-mers \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Build kallisto index of transcriptome for sim\n",
    "! kallisto index -i transcripts_sim.idx arc_sim.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 75, sd = 10\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 10,000\n",
      "[index] number of equivalence classes: 26\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: arc_sim.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 100,000 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 64 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Map reads against transcriptome for sim\n",
    "! kallisto quant -i transcripts_sim.idx -o output_sim --single -l 75 -s 10 arc_sim.fastq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_id\tlength\teff_length\test_counts\ttpm\n",
      "\n",
      "Arc1\t4000\t3926\t2688.88\t19817.9\n",
      "\n",
      "Arc2\t2000\t1926\t3403.34\t51131.1\n",
      "\n",
      "Arc3\t3000\t2926\t28558\t282416\n",
      "\n",
      "Arc4\t4000\t3926\t10732\t79098.1\n",
      "\n",
      "Arc5\t4000\t3926\t12332.1\t90891.5\n",
      "\n",
      "Arc6\t3000\t2926\t1867.71\t18470.2\n",
      "\n",
      "Arc7\t2000\t1926\t6024.08\t90504.5\n",
      "\n",
      "Arc8\t2000\t1926\t5364.22\t80590.9\n",
      "\n",
      "Arc9\t3000\t2926\t3070.9\t30368.8\n",
      "\n",
      "Arc10\t3000\t2926\t25958.7\t256711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at abundance.tsv output\n",
    "with open(\"output_sim/abundance.tsv\",'r') as infile:   \n",
    "    for line in infile:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Arcs 1, 2, 3, 5, 6, 8, 9, 10, kallisto's tpm output is closer to Moriarty's result compared to mine (top table), even with the \"true\" abundances used. Kallisto's inferred TPMs here are off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arc is unique in that it is circular and the transcipts overlap, could this be an issue? I'd like to remove the overlap so that arc is now treated like a linear sequence with no transcripts overlapping. In this no overlap condition, each read should only map to one Arc segment since there are no overlaps and the reads should be long enough to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file arc_sim_2.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 10 contigs and contains 5700 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 75, sd = 10\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 5,700\n",
      "[index] number of equivalence classes: 10\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: arc_sim_2.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 100,000 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n",
      "target_id\tlength\teff_length\test_counts\ttpm\n",
      "\n",
      "Arc1\t800\t726\t841\t5919.74\n",
      "\n",
      "Arc2\t400\t326\t3907\t61244.8\n",
      "\n",
      "Arc3\t600\t526\t29271\t284377\n",
      "\n",
      "Arc4\t800\t726\t11016\t77540.8\n",
      "\n",
      "Arc5\t800\t726\t12771\t89894.1\n",
      "\n",
      "Arc6\t600\t526\t772\t7500.23\n",
      "\n",
      "Arc7\t400\t326\t5970\t93583.6\n",
      "\n",
      "Arc8\t400\t326\t5958\t93395.5\n",
      "\n",
      "Arc9\t600\t526\t2202\t21393.1\n",
      "\n",
      "Arc10\t600\t526\t27292\t265151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix everything except shorten each arc locus' length so there is no overlap and re-run simulation and kallisto\n",
    "# Proportions are same as before\n",
    "L = [.8 * len_S, .4 * len_S, .6 * len_S, .8 * len_S, .8 * len_S,\n",
    "     .6 * len_S, .4 * len_S, .4 * len_S, .6 * len_S, .6 * len_S,]\n",
    "L = [int(i) for i in L]\n",
    "\n",
    "# Generate new shortened Arc1 to Arc10 transcipts\n",
    "arc_trans = {}\n",
    "with open('arc_sim_2.fasta','w') as outfile:\n",
    "    for arc in range(S):\n",
    "        name = '>Arc' + str(arc + 1)\n",
    "        start = arc * len_S\n",
    "        end = start + L[arc]\n",
    "        seq = arc_seq[start:end]\n",
    "        arc_trans[name] = seq\n",
    "        outfile.write(name + '\\n')\n",
    "        outfile.write(seq + '\\n')\n",
    "        \n",
    "# Generate reads\n",
    "with open('arc_sim_2.fastq','w') as outfile:\n",
    "    for read in range(N):\n",
    "        # sample transcipt\n",
    "        i = np.random.choice(range(0,T), p=V) # generates integer between 0-9 based on nucleotide abundance\n",
    "        # pick random start position\n",
    "        start = np.random.randint(0, L[i] - len_R)\n",
    "        seq = arc_trans['>Arc' + str(i + 1)][start:start + len_R] \n",
    "        # above: need to add one to convert python 0-9 indexing to arc 1-10\n",
    "        outfile.write('@read' + str(read) + '\\n')\n",
    "        outfile.write(seq + '\\n')\n",
    "        outfile.write('+' + '\\n')\n",
    "        outfile.write('I' * len_R + '\\n')\n",
    "        \n",
    "# Build kallisto index of transcriptome for sim\n",
    "! kallisto index -i transcripts_sim_2.idx arc_sim_2.fasta\n",
    "\n",
    "# Map reads against transcriptome for sim\n",
    "! kallisto quant -i transcripts_sim_2.idx -o output_sim_2 --single -l 75 -s 10 arc_sim_2.fastq \n",
    "\n",
    "# Look at abundance.tsv output\n",
    "with open(\"output_sim_2/abundance.tsv\",'r') as infile:   \n",
    "    for line in infile:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no overlapping Arc transcipts, the results are now much closer to my TPM than Moriarty's. (I did not rigorously compare the differences with significance testing, but I can tell this is much closer to the \"truth\" compared to before via visual inspection of the values.) Kallisto seems to work fine on transcipts without overlaps, where it has no trouble mapping reads to unique transcripts. For a template transcipt with many overlaps like Arc, kallisto seems to have trouble solving this particular \"non-unique problem\" as discussed in class, where reads can potentially map to multiple transcipts. Kallisto's expectation maximization algorithm produces a reasonable result, with most inferred TPMs within the same order of magnitude compared to the true TPMs. However, with an additional source of deviation during expectation maximization on top of already existing randomness, the inferred TPM deviates farther from the truth.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Transcript</th>\n",
    "      <th>\"True\" TPM</th>\n",
    "      <th>TPM w/o overlap</th>\n",
    "      <th>TPM w/ overlap</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Arc1</td>\n",
    "      <td>6000</td>      \n",
    "      <td>5920</td>\n",
    "      <td>19818</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Arc2</td>\n",
    "      <td>58000</td>      \n",
    "      <td>61245</td>\n",
    "      <td>51131</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc3</td>\n",
    "      <td>290000</td>      \n",
    "      <td>284377</td>\n",
    "      <td>282416</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc4</td>\n",
    "      <td>83000</td>      \n",
    "      <td>77541</td>\n",
    "      <td>79098</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc5</td>\n",
    "      <td>94000</td>      \n",
    "      <td>89894</td>\n",
    "      <td>90892</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc6</td>\n",
    "      <td>7800</td>      \n",
    "      <td>7500</td>\n",
    "      <td>18470</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc7</td>\n",
    "      <td>87000</td>      \n",
    "      <td>93584</td>\n",
    "      <td>90504</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc8</td>\n",
    "      <td>88000</td>      \n",
    "      <td>93396</td>\n",
    "      <td>80591</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc9</td>\n",
    "      <td>22000</td>      \n",
    "      <td>21393</td>\n",
    "      <td>30369</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>Arc10</td>\n",
    "      <td>270000</td>      \n",
    "      <td>265151</td>\n",
    "      <td>256711</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
